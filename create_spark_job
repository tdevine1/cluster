# make directory structure for scala code
mkdir -p [projectname]/src/main/scala

# move into [projectname]
cd [projectname]

# make sbt file
nano [projectname].sbt

# copy info into file
name := "[projectname]"
 
version := "1.0"

scalaVersion := "2.11.8"

libraryDependencies += "org.apache.spark" %% "spark-core" % "1.6.1"

# make the eclipse empty project
sbt eclipse

# edit the project in eclipse, add external dependencies and then to repackage
reload

sbt reload
sbt eclipse with-source=true

# package the code to make a runnable job
sbt package

# submit the job
spark-submit --class [main_class_name] --master yarn --deploy-mode cluster --driver-memory 4g --executor-memory 2g --executor-cores 3 --queue default [full_path_to_projectname]_2.11-1.0.jar
